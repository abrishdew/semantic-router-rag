{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Routing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "import PyPDF2\n",
    "\n",
    "# Initialize BERT model and tokenizer for semantic similarity scoring\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_file_path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfFileReader(f)\n",
    "        for page_num in range(reader.numPages):\n",
    "            page = reader.getPage(page_num)\n",
    "            text += page.extractText()\n",
    "    return text\n",
    "\n",
    "# Function to compute similarity scores between input question and text\n",
    "def compute_similarity(input_question, text):\n",
    "    # Tokenize input question\n",
    "    input_question_tokens = bert_tokenizer(input_question, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_question_ids = input_question_tokens[\"input_ids\"]\n",
    "\n",
    "    # Tokenize text\n",
    "    text_tokens = bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    text_ids = text_tokens[\"input_ids\"]\n",
    "\n",
    "    # Compute embeddings for input question and text\n",
    "    with torch.no_grad():\n",
    "        _, input_question_embedding = bert_model(**input_question_tokens)\n",
    "        _, text_embeddings = bert_model(**text_tokens)\n",
    "\n",
    "    # Compute similarity scores using cosine similarity\n",
    "    similarity_scores = torch.nn.functional.cosine_similarity(input_question_embedding, text_embeddings, dim=1)\n",
    "    return similarity_scores.numpy()\n",
    "\n",
    "# Sample input question\n",
    "input_question = \"What is the capital of Canada?\"\n",
    "\n",
    "# Extract text from PDF file\n",
    "pdf_file_path = \"path/to/your/pdf/file.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "# Compute similarity scores\n",
    "similarity_scores = compute_similarity(input_question, pdf_text)\n",
    "\n",
    "# Print similarity scores\n",
    "print(\"Similarity Scores:\")\n",
    "print(similarity_scores)\n",
    "\n",
    "# Initialize RAG tokenizer, retriever, and generator\n",
    "rag_tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
    "rag_retriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "rag_generator = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")\n",
    "\n",
    "# Encode input question\n",
    "input_ids = rag_tokenizer(input_question, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Retrieve relevant passages\n",
    "retrieved_docs = rag_retriever.retrieve(input_ids)\n",
    "\n",
    "# Generate answer based on retrieved passages\n",
    "output = rag_generator.generate(input_ids, retrieved_docs=retrieved_docs)\n",
    "\n",
    "# Decode and print the answer\n",
    "answer = rag_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
